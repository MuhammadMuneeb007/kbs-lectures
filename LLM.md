# üöÄ Complete CS Student Resource Guide - Australia & Global

## üìë **Table of Contents**
1. [üîê Cybersecurity Resources](#cybersecurity)
2. [üíª Programming & Development](#programming)
3. [üé¨ YouTube Learning Channels](#youtube-channels)
4. [üì± Social Media & Communities](#communities)
5. [üìö GitHub Learning Resources](#github-resources)
6. [üéì Student Benefits & Tools](#student-benefits)
7. [üíº Internships & Job Hunting](#internships-jobs)
8. [üá¶üá∫ Australia-Specific Resources](#australia-specific)
9. [üé§ Free Webinars & Events](#webinars-events)
10. [üèÜ Competitions & Challenges](#competitions)
11. [üöÄ Success Roadmap](#success-roadmap)
12. [üí° Additional Learning Resources](#additional-resources)

---

## üîê **Cybersecurity Resources** {#cybersecurity}

### **üìã Foundational Courses**

| **Subject**        | **Platform/Provider** | **Link**                                                                                            | **Certificate Type** | **Key Features**                                                                                             |
| ------------------ | --------------------- | --------------------------------------------------------------------------------------------------- | -------------------- | ------------------------------------------------------------------------------------------------------------ |
| **Cyber Security** | EC-Council            | https://www.eccouncil.org/cybersecurity-exchange/cyber-novice/free-cybersecurity-courses-beginners/ | Free Certificate     | Network Defense Essentials (N\|DE), Ethical Hacking Essentials (E\|HE), Digital Forensics Essentials (D\|FE) |
| **Cyber Security** | ISC2                  | https://www.isc2.org/landing/1mcc                                                                   | Free Certificate     | Certified in Cybersecurity (CC) - 1 million free certifications                                              |
| **Cyber Security** | Google/Coursera       | https://grow.google/certificates/cybersecurity/                                                     | Paid Certificate     | Google Cybersecurity Certificate - 7-day free trial                                                          |
| **Cyber Security** | Great Learning        | https://www.mygreatlearning.com/cybersecurity/free-courses                                          | Free Certificate     | Multiple cybersecurity fundamentals courses                                                                  |
| **Cyber Security** | Palo Alto Networks    | https://www.paloaltonetworks.com/cyberpedia/free-cybersecurity-education-courses                    | Free Access          | Fundamentals of Cybersecurity, Cloud Security, SOC                                                           |

### **üîç Specialized Cybersecurity Tracks**

| **Subject**             | **Platform/Provider** | **Link**                                                                           | **Certificate Type** | **Key Features**                                          |
| ----------------------- | --------------------- | ---------------------------------------------------------------------------------- | -------------------- | --------------------------------------------------------- |
| **Digital Forensics**   | EC-Council            | https://www.eccouncil.org/train-certify/digital-forensics-essentials-dfe/          | Free Certificate     | Digital Forensics Essentials (D\|FE) with CTF challenges  |
| **Digital Forensics**   | Coursera              | https://www.coursera.org/courses?query=digital+forensics                           | Free Audit/Paid Cert | Various university courses, audit for free                |
| **Penetration Testing** | Coursera              | https://www.coursera.org/learn/ibm-penetration-testing-threat-hunting-cryptography | Free Audit/Paid Cert | IBM Penetration Testing, Threat Hunting, and Cryptography |
| **Penetration Testing** | Class Central         | https://www.classcentral.com/subject/pentesting                                    | Free & Paid          | 2100+ penetration testing courses                         |
| **Penetration Testing** | Udemy                 | https://www.udemy.com/topic/cyber-security/free/                                   | Free Courses         | Various free ethical hacking and pentesting courses       |

---

## üíª **Programming & Development Resources** {#programming}

### **üìã Core Programming Courses**

| **Subject**                  | **Platform/Provider** | **Link**                                                               | **Certificate Type** | **Key Features**                                         |
| ---------------------------- | --------------------- | ---------------------------------------------------------------------- | -------------------- | -------------------------------------------------------- |
| **Intermediate Programming** | GeeksforGeeks         | https://www.geeksforgeeks.org/courses/python-course-certification-free | Free Certificate     | Python intermediate concepts, data structures, OOP       |
| **Intermediate Programming** | freeCodeCamp          | https://www.freecodecamp.org/news/free-certificates/                   | Free Certificate     | 1000+ free developer certifications                      |
| **Intermediate Programming** | Codecademy            | https://www.codecademy.com/catalog/language/python                     | Free & Paid          | Intermediate Python, functional programming, concurrency |
| **Advanced Programming**     | Coursera              | https://www.coursera.org/courses?query=python                          | Free Audit/Paid Cert | Advanced Python courses from top universities            |
| **Advanced Programming**     | Google Developers     | https://developers.google.com/edu/python                               | Free Access          | Google's Python Class - used internally at Google        |
| **Advanced Programming**     | Scaler                | https://www.scaler.com/topics/course/python-for-beginners/             | Free Certificate     | 9+ hours comprehensive Python course                     |

## üñ•Ô∏è **Programming Language Specializations**

| **Language**   | **Platform/Provider** | **Link**                                                  | **Certificate Type** | **Key Features**                            |
| -------------- | --------------------- | --------------------------------------------------------- | -------------------- | ------------------------------------------- |
| **Java**       | Oracle                | https://education.oracle.com/java                         | Free Courses         | Official Java tutorials and documentation   |
| **Java**       | Codecademy            | https://www.codecademy.com/learn/learn-java               | Free & Paid          | Interactive Java programming                |
| **JavaScript** | MDN Web Docs          | https://developer.mozilla.org/en-US/docs/Learn/JavaScript | Free                 | Comprehensive JavaScript guide              |
| **JavaScript** | JavaScript.info       | https://javascript.info/                                  | Free                 | Modern JavaScript tutorial                  |
| **Python**     | Python.org            | https://docs.python.org/3/tutorial/                       | Free                 | Official Python tutorial                    |
| **Python**     | Real Python           | https://realpython.com/                                   | Free & Paid          | High-quality Python tutorials               |
| **C++**        | Learn-C++             | https://www.learncpp.com/                                 | Free                 | Comprehensive C++ tutorial                  |
| **C++**        | Google for Education  | https://developers.google.com/edu/c++                     | Free                 | Google's C++ course                         |
| **Go**         | Go by Example         | https://gobyexample.com/                                  | Free                 | Hands-on introduction to Go                 |
| **Go**         | A Tour of Go          | https://tour.golang.org/                                  | Free                 | Interactive Go tutorial                     |
| **Rust**       | Rust Book             | https://doc.rust-lang.org/book/                           | Free                 | The official Rust programming language book |
| **Swift**      | Apple Developer       | https://developer.apple.com/swift/resources/              | Free                 | Official Swift resources                    |
| **Kotlin**     | Kotlin Koans          | https://kotlinlang.org/docs/koans.html                    | Free                 | Interactive Kotlin exercises                |
| **Ruby**       | Ruby Docs             | https://www.ruby-lang.org/en/documentation/               | Free                 | Official Ruby documentation                 |
| **PHP**        | PHP Manual            | https://www.php.net/manual/en/                            | Free                 | Official PHP documentation                  |
| **Scala**      | Scala Exercises       | https://www.scala-exercises.org/                          | Free                 | Interactive Scala exercises                 |

## ü§ñ **Large Language Models (LLM) & AI Development**

### **üéì LLM Fundamentals & Theory**

| **Subject**                        | **Platform/Provider** | **Link**                                                    | **Certificate Type** | **Key Features**                                  |
| ---------------------------------- | --------------------- | ----------------------------------------------------------- | -------------------- | ------------------------------------------------- |
| **Deep Learning Specialization**   | Coursera (DeepLearning.AI) | https://www.coursera.org/specializations/deep-learning | Free Audit/Paid Cert | Neural networks, backpropagation, optimization    |
| **Natural Language Processing**    | Coursera (DeepLearning.AI) | https://www.coursera.org/specializations/natural-language-processing | Free Audit/Paid Cert | NLP fundamentals, transformers, attention         |
| **Transformer Models Course**     | Hugging Face          | https://huggingface.co/learn/nlp-course                      | Free                 | BERT, GPT, T5, practical implementation           |
| **CS224N: NLP with Deep Learning** | Stanford              | https://web.stanford.edu/class/cs224n/                       | Free                 | Academic depth, research-level content            |
| **MIT 6.034 Artificial Intelligence** | MIT OpenCourseWare | https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/ | Free | AI fundamentals from MIT |
| **Fast.AI Practical Deep Learning** | Fast.AI              | https://www.fast.ai/                                        | Free                 | Practical, code-first approach to deep learning   |
| **Introduction to Large Language Models** | Google Cloud     | https://www.cloudskillsboost.google/course_templates/539    | Free                 | LLM concepts, architecture, applications           |

### **üîß LLM Fine-tuning & Training Platforms**

| **Platform**              | **Link**                                    | **Speciality**             | **Free Tier**               | **Best For**                    |
| -------------------------- | ------------------------------------------- | -------------------------- | --------------------------- | ------------------------------- |
| **Hugging Face**           | https://huggingface.co/                     | Model hub & fine-tuning    | Generous free tier          | Experimentation & sharing       |
| **Google Colab**           | https://colab.research.google.com/          | GPU/TPU training           | Free GPU/TPU hours          | Learning & prototyping          |
| **Kaggle Notebooks**       | https://www.kaggle.com/code                 | Dataset + GPU training     | 30 hours/week GPU           | Competitions & datasets         |
| **Paperspace Gradient**    | https://www.paperspace.com/gradient        | Cloud ML training          | Free tier available         | Serious training projects       |
| **Unsloth**                | https://github.com/unslothai/unsloth        | Efficient fine-tuning      | Open source                 | Memory-efficient training       |
| **Axolotl**                | https://github.com/OpenAccess-AI-Collective/axolotl | Fine-tuning framework | Open source          | Production fine-tuning          |
| **LitGPT**                 | https://github.com/Lightning-AI/litgpt     | Lightning-based training   | Open source                 | Research & experimentation      |
| **AutoTrain**              | https://huggingface.co/autotrain            | No-code fine-tuning        | Paid service                | Quick deployments               |
| **Modal**                  | https://modal.com/                          | Serverless GPU compute     | Free tier available         | Scalable training jobs          |
| **RunPod**                 | https://runpod.io/                          | GPU cloud platform         | Pay-per-use                 | Cost-effective GPU access       |
| **Vast.ai**                | https://vast.ai/                            | Decentralized GPU market   | Competitive pricing         | Budget-conscious training       |
| **Lambda Labs**            | https://lambdalabs.com/                     | AI-optimized cloud         | On-demand pricing           | High-performance training       |

### **üõ†Ô∏è LLM Development Tools & Frameworks**

| **Tool/Framework**         | **Link**                                    | **Focus**                  | **Language** | **Key Features**                        |
| -------------------------- | ------------------------------------------- | -------------------------- | ------------ | --------------------------------------- |
| **PyTorch**                | https://pytorch.org/                        | Deep learning framework    | Python       | Research-friendly, dynamic graphs       |
| **TensorFlow**             | https://www.tensorflow.org/                 | Deep learning framework    | Python       | Production-ready, static graphs         |
| **Transformers Library**   | https://github.com/huggingface/transformers | Pre-trained models         | Python       | Easy access to SOTA models             |
| **LangChain**              | https://github.com/langchain-ai/langchain   | LLM application framework  | Python       | Chains, agents, memory for LLM apps     |
| **LlamaIndex**             | https://github.com/run-llama/llama_index    | Data framework for LLMs    | Python       | RAG, document indexing, querying        |
| **Ollama**                 | https://ollama.ai/                          | Local LLM deployment       | Multi        | Run LLMs locally on your machine        |
| **vLLM**                   | https://github.com/vllm-project/vllm       | High-performance inference | Python       | Fast serving of large models            |
| **DeepSpeed**              | https://github.com/microsoft/DeepSpeed     | Training optimization      | Python       | Memory efficient, large model training  |
| **Accelerate**             | https://github.com/huggingface/accelerate   | Distributed training       | Python       | Multi-GPU/TPU training made simple      |
| **Triton**                 | https://github.com/triton-lang/triton       | GPU programming            | Python       | Write custom CUDA kernels easily       |
| **TensorRT-LLM**           | https://github.com/NVIDIA/TensorRT-LLM     | NVIDIA inference optimization | Python    | Optimized inference for NVIDIA GPUs    |
| **Text Generation Inference** | https://github.com/huggingface/text-generation-inference | Production serving | Rust/Python | High-performance text generation API |

### **üìö LLM Fine-tuning Techniques & Methods**

| **Technique**              | **Description**                           | **Use Case**               | **Memory Efficiency** | **Learning Resources**                    |
| -------------------------- | ----------------------------------------- | -------------------------- | --------------------- | ----------------------------------------- |
| **Full Fine-tuning**       | Update all model parameters               | Domain adaptation          | Low                   | Standard PyTorch/HF tutorials            |
| **LoRA (Low-Rank Adaptation)** | Low-rank matrix updates               | Parameter-efficient        | High                  | https://github.com/microsoft/LoRA        |
| **QLoRA (Quantized LoRA)** | 4-bit quantization + LoRA                | Memory-constrained setups  | Very High             | https://github.com/artidoro/qlora        |
| **AdaLoRA**                | Adaptive rank allocation                  | Optimal parameter use      | High                  | Research papers and implementations      |
| **Prefix Tuning**          | Learn prefix tokens                       | Task-specific adaptation   | Very High             | Academic papers and code repos           |
| **P-Tuning v2**            | Learnable prompt embeddings               | Few-shot learning          | Very High             | Research implementations                 |
| **InstructGPT Style**      | RLHF (Reinforcement Learning from Human Feedback) | Alignment training | Medium | OpenAI papers and implementations    |
| **DPO (Direct Preference Optimization)** | Direct preference learning    | Alignment without RL       | Medium                | Recent research papers                   |
| **ORPO (Odds Ratio Preference Optimization)** | Unified preference training | Single-stage alignment | Medium | 2024 alignment research papers |
| **DoRA (Weight-Decomposed Low-Rank Adaptation)** | Enhanced LoRA variant | Better adaptation quality | High | Latest PEFT research implementations |
| **MoLoRA (Mixture of LoRAs)** | Multiple specialized adapters | Multi-task fine-tuning | High | 2024 multi-task learning papers |
| **AdapterFusion**          | Combine multiple task adapters           | Knowledge composition      | Very High             | Adapter-hub implementations              |

### **üî¨ Advanced LLM Training & Research**

| **Topic**                  | **Resource**                                | **Difficulty** | **Focus**                           |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Transformer Architecture** | "Attention is All You Need" paper        | Advanced       | Understanding the foundation        |
| **GPT Architecture**       | OpenAI GPT papers (1, 2, 3, 4)             | Advanced       | Autoregressive language modeling    |
| **BERT & Bidirectional Models** | Google BERT paper                     | Intermediate   | Bidirectional context understanding |
| **T5 & Encoder-Decoder**   | Google T5 paper                             | Intermediate   | Text-to-text transfer transformer   |
| **Scaling Laws**           | "Scaling Laws for Neural Language Models"   | Advanced       | Model size vs performance           |
| **Constitutional AI**      | Anthropic papers                            | Advanced       | AI safety and alignment             |
| **Retrieval Augmented Generation** | RAG papers and implementations      | Intermediate   | Knowledge integration               |
| **Multi-modal LLMs**       | CLIP, DALL-E, GPT-4V papers                | Advanced       | Vision + language models            |

### **üéØ Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pixtral**                | Mistral AI       | 12B multimodal | Apache 2.0     | Vision-language understanding       |

### **üîç LLM Evaluation & Benchmarking**

| **Benchmark/Evaluation**   | **Link**                                    | **Focus**                  | **Metrics**                         |
| -------------------------- | ------------------------------------------- | -------------------------- | ----------------------------------- |
| **GLUE/SuperGLUE**         | https://gluebenchmark.com/                  | General language understanding | Accuracy across multiple tasks  |
| **MMLU**                   | https://github.com/hendrycks/test           | Massive multitask language understanding | Knowledge across domains |
| **HumanEval**              | https://github.com/openai/human-eval       | Code generation            | Functional correctness              |
| **BigBench**               | https://github.com/google/BIG-bench        | Beyond the imitation game  | Diverse reasoning tasks             |
| **HellaSwag**              | https://rowanzellers.com/hellaswag/         | Commonsense reasoning      | Story completion accuracy           |
| **TruthfulQA**             | https://github.com/sylinrl/TruthfulQA      | Truthfulness               | Factual accuracy                    |
| **EleutherAI LM Eval**     | https://github.com/EleutherAI/lm-evaluation-harness | Comprehensive evaluation | Multiple benchmark suite     |
| **HELM**                   | https://crfm.stanford.edu/helm/             | Holistic evaluation        | Fairness, robustness, efficiency   |
| **MT-Bench**               | https://github.com/lm-sys/FastChat         | Multi-turn conversations   | Conversational ability              |
| **AlpacaEval**             | https://github.com/tatsu-lab/alpaca_eval   | Instruction following      | Win rate against reference models   |
| **LMSYS Chatbot Arena**    | https://chat.lmsys.org/                     | Human preference           | ELO ratings from human voting       |
| **LiveBench**              | https://livebench.ai/                       | Contamination-free eval    | Monthly updated questions           |
| **MMMU**                   | https://mmmu-benchmark.github.io/           | Multimodal understanding   | College-level multimodal reasoning  |
| **MuSR**                   | https://github.com/zayne-sprague/MuSR      | Multistep reasoning        | Complex reasoning chains            |

### **üéì Hands-on LLM Projects & Tutorials**

| **Project Type**           | **Resource/Tutorial**                       | **Difficulty** | **Skills Developed**                |
| -------------------------- | ------------------------------------------- | -------------- | ----------------------------------- |
| **Basic Text Generation**  | Hugging Face Course - Chapter 1-3          | Beginner       | Model loading, generation basics    |
| **Custom Dataset Fine-tuning** | Unsloth tutorials                       | Intermediate   | Data preparation, training loops    |
| **Chatbot Development**    | LangChain + Streamlit tutorials             | Intermediate   | Application development             |
| **RAG System**             | LlamaIndex tutorials                        | Intermediate   | Document retrieval and generation   |
| **Model Quantization**     | GPTQ, AWQ implementation guides             | Advanced       | Model compression techniques        |
| **Local LLM Deployment**   | Ollama + Docker setup guides               | Intermediate   | Production deployment               |
| **LLM Evaluation**         | BLEU, ROUGE, human evaluation setups       | Intermediate   | Model assessment techniques         |
| **Multi-GPU Training**     | DeepSpeed + Accelerate tutorials            | Advanced       | Distributed computing               |

### **üíæ Popular LLM Models & Checkpoints**

| **Model Family**           | **Provider**     | **Size Range** | **License**    | **Best For**                        |
| -------------------------- | ---------------- | -------------- | -------------- | ----------------------------------- |
| **Llama 2/3/3.1/3.2/3.3** | Meta             | 1B - 405B      | Custom License | General purpose, fine-tuning        |
| **Mistral/Mixtral**        | Mistral AI       | 7B - 8x22B     | Apache 2.0     | Commercial use, efficiency          |
| **Qwen/Qwen2/Qwen2.5**    | Alibaba          | 0.5B - 72B     | Apache 2.0     | Multilingual, coding                |
| **Gemma/Gemma 2**          | Google           | 2B - 27B       | Custom License | Research, lightweight deployment    |
| **Phi-3/Phi-4**            | Microsoft        | 3.8B - 14B     | MIT License    | Small, efficient models             |
| **Yi**                     | 01.AI            | 6B - 34B       | Apache 2.0     | Multilingual capabilities           |
| **Code Llama**             | Meta             | 7B - 34B       | Custom License | Code generation and understanding   |
| **StarCoder/StarCoder2**   | BigCode          | 1B - 15B       | BigCode License| Code-specific tasks                 |
| **DeepSeek Coder**         | DeepSeek         | 1.3B - 33B     | Custom License | Advanced coding capabilities        |
| **Claude 3.5 Sonnet**      | Anthropic        | API only       | Commercial     | Advanced reasoning & safety         |
| **Command R/R+**           | Cohere           | 35B - 104B     | Custom License | RAG-optimized models               |
| **Aya 23**                 | Cohere           | 8B - 35B       | Apache 2.0     | Multilingual (101 languages)       |
| **Pix
